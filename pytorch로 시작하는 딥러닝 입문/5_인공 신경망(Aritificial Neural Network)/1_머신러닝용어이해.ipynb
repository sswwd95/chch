{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 머신 러닝 모델의 평가\r\n",
    "\r\n",
    "## train, validation, test로 나누는 이유 : \r\n",
    "validation은 모델의 성능을 평가하기 위한 용도가 아니라, 모델의 성능을 조정하기 위한 용도다. 과적합이 되고 있는지 판단하거나 하이퍼파라미터(초매개변수)의 조정을 위한 용도다. \r\n",
    "\r\n",
    "1. 하이퍼파라미터 : 사용자가 직접 정해줄 수 있는 변수 \r\n",
    "- learning rate, 은닉층의 수, 뉴런의 수, 드롭아웃 비율 등  \r\n",
    "- 사람이 정하는 변수 </n>\r\n",
    "2. 매개변수 : 가중치와 편향과 같은 학습을 통해 바뀌어져가는 변수 \r\n",
    "- 모델이 학습하는 과정에서 얻어지는 값 \r\n",
    "- 기계가 훈련을 통해서 바꾸는 변수</n>\r\n",
    "\r\n",
    "train = 문제지\r\n",
    "val = 모의고사\r\n",
    "test = 수능 시험\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 분류와 회귀\r\n",
    "\r\n",
    "### 1) 이진 분류 문제 : 둘 중 하나의 답을 정하는 문제\r\n",
    "### 2) 다중 분류 문제 : 세 개 이상의 정해진 선택지 중에서 답을 정하는 문제\r\n",
    "### 3) 회귀 문제 : 연속된 값을 결과로 가진다. 주가예측, 생산량 예측, 지수 예측 등이 이에 속한다.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 지도 학습과 비지도 학습\r\n",
    "\r\n",
    "### 1) 지도 학습 : label이라는 정답과 함께 학습\r\n",
    "### 2) 비지도 학습 : 목적 데이터(또는 label)가 없는 학습. ex) 군집(clustering)이나 차원 축소\r\n",
    "### 3) 강화 학습 : 어떤 환경 내에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 샘플과 특성\r\n",
    "하나의 행을 sample이라 부르고(데이터베이스에서는 레코드라고 부르는 단위), y를 예측하기 위한 각각의 독립 변수 x를 특성(feature)이라고 부른다.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 혼돈 행렬(Confusion Matrix)\r\n",
    "맞춘 문제수를 전체 문제수로 나눈 값을 정확도(accuracy)라고 한다.\r\n",
    "맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주는 것 :  혼돈 행렬\r\n",
    "\r\n",
    "| |참|거짓|\r\n",
    "|:---:|:---:|:---:|\r\n",
    "|참| TP|FN|\r\n",
    "|거짓|FP|TN|\r\n",
    "\r\n",
    "\r\n",
    "1. 정밀도(precision)\r\n",
    "양성이라고 대답한 전체 케이스에 대한 TP의 비율  \r\n",
    "\r\n",
    "* $\\frac{TP}{TP+FP}$\r\n",
    "\r\n",
    "2. 재현율(recall)\r\n",
    "실제값이 양성인 데이터의 전체 개수에 대해서 TP의 비율. 양성인 데이터 중에서 얼마나 양성인지를 예측(재현)했는지를 나타낸다.  \r\n",
    "\r\n",
    "* $\\frac{TP}{TP+FN}$\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. 과적합과 과소적합\r\n",
    "\r\n",
    "### 1. 과적합 : 훈련 데이터를 과하게 학습한 경우\r\n",
    "* 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 높아지는 상황\r\n",
    "* dropout, early stopping 방법을 사용하여 과적합을 막는다.\r\n",
    "### 2. 과소적합 : 훈련을 덜 한 상태로, 정확도가 낮다."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}