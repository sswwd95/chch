{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 데이터 양 늘리기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터의 양이 적을 경우에는 의도적으로 기존의 데이터를 조금씩 변형하고 추가하여 데이터의 양을 늘리기도 하는데 이를 데이터 증식 또는 증강(Data Augmentation)이라고 합니다. 이미지의 경우에는 데이터 증식이 많이 사용되는데 이미지를 돌리거나 노이즈를 추가하고, 일부분을 수정하는 등으로 데이터를 증식시킵니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 모델의 복잡도 줄이기\r\n",
    "* 인공 신경망의 복잡도는 은닉층(hidden layer)의 수나 매개변수의 수 등으로 결정\r\n",
    "* 인공 신경망에서는 모델에 있는 매개변수들의 수를 모델의 수용력(capacity)이라고 하기도 합니다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "class Architecture1(nn.Module):\r\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\r\n",
    "        super(Architecture1, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\r\n",
    "        self.relu = nnReLU()\r\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.fc1(x)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.fc2(out)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.fc3(out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Architecture1(nn.Module):\r\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\r\n",
    "        super(Architecture1, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.fc1(x)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.fc2(out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 가중치 규제 적용하기\r\n",
    "복잡한 모델이 간단한 모델보다 과적합될 가능성이 높습니다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가합니다. L1 노름이라고도 합니다.\r\n",
    "L2 규제 : 모든 가중치 w들의 제곱합을 비용 함수에 추가합니다. L2 노름이라고도 합니다.\r\n",
    "\r\n",
    "이 두 식 모두 비용 함수를 최소화하기 위해서는 가중치 w들의 값이 작아져야 한다는 특징이 있다.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [L1 Regularization]\r\n",
    "L1의 경우 절대값의 합도 최소가 되어야 하기 때문에 가중치 w의 값들은 0 또는 0에 가까이 작아져야 하므로 어떤 특성들은 모델을 만들 때 거의 사용되지 않게 된다.\r\n",
    "\r\n",
    "$H(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4}$ 수식에서 L1규제를 사용하여 w3의 값이 0이 되면 특성을 잃게 된다.\r\n",
    "\r\n",
    "L1 규제는 어떤 특성들이 모델에 영향을 주고 있는지를 정확히 판단하고자 할 때 유용하다.\r\n",
    "* L1 Regularization 의 경우 미분 불가능한 점이 있기 때문에 Gradient-base learning 에는 주의가 필요하다.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [L2 Regularization]\r\n",
    "L2 규제는 L1 규제와는 달리 가중치들의 제곱을 최소화하므로 w의 값이 완전히 0이 되기보다는 0에 가까워지기는 경향을 보인다. 어떤 특성이 모델에 영향을 주는지 알아야할 필요가 없다면 L2를 쓰는게 더 좋다. 인공 신경망에서 L2 규제는 가중치 감소(weight decay)라고도 부른다.\r\n",
    "\r\n",
    "* 파이토치에서는 옵티마이저의 weight_decay 매개변수를 설정하므로서 L2 규제를 적용\r\n",
    "* weight_decay 매개변수의 기본값은 0이다. \r\n",
    "* weight_decay 매개변수에 다른 값을 설정할 수도 있다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Architecture1(10, 20, 2)\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 드롭아웃\r\n",
    "드롭아웃의 비율을 0.5로 한다면 학습 과정마다 랜덤으로 절반의 뉴런을 사용하지 않고, 절반의 뉴런만을 사용\r\n",
    "드롭아웃은 신경망 학습 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적\r\n",
    "학습 시에 인공 신경망이 특정 뉴런 또는 특정 조합에 너무 의존적이게 되는 것을 방지해주고, 매번 랜덤 선택으로 뉴런들을 사용하지 않으므로 서로 다른 신경망들을 앙상블하여 사용하는 것 같은 효과를 내어 과적합을 방지합니다.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}