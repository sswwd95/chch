{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 깊은 CNN으로 MNIST 분류하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torchvision.datasets as dsets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn.init\r\n",
    "\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "# 랜덤 시드 고정\r\n",
    "torch.manual_seed(777)\r\n",
    "\r\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)\r\n",
    "\r\n",
    "\r\n",
    "learning_rate = 0.001\r\n",
    "training_epochs = 15\r\n",
    "batch_size = 100\r\n",
    "\r\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\r\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\r\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\r\n",
    "                          download=True)\r\n",
    "\r\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\r\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\r\n",
    "                         transform=transforms.ToTensor(), # 텐서로 변환\r\n",
    "                         download=True)\r\n",
    "\r\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\r\n",
    "                                          batch_size=batch_size,\r\n",
    "                                          shuffle=True,\r\n",
    "                                          drop_last=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sswwd\\anaconda3\\envs\\chch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class CNN(torch.nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(CNN, self).__init__()\r\n",
    "        self.keep_prob = 0.5\r\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\r\n",
    "        #    Conv     -> (?, 28, 28, 32)\r\n",
    "        #    Pool     -> (?, 14, 14, 32)\r\n",
    "        self.layer1 = torch.nn.Sequential(\r\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\r\n",
    "            torch.nn.ReLU(),\r\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\r\n",
    "        #    Conv      ->(?, 14, 14, 64)\r\n",
    "        #    Pool      ->(?, 7, 7, 64)\r\n",
    "        self.layer2 = torch.nn.Sequential(\r\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\r\n",
    "            torch.nn.ReLU(),\r\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\r\n",
    "        #    Conv      ->(?, 7, 7, 128)\r\n",
    "        #    Pool      ->(?, 4, 4, 128)\r\n",
    "        self.layer3 = torch.nn.Sequential(\r\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\r\n",
    "            torch.nn.ReLU(),\r\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\r\n",
    "\r\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\r\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\r\n",
    "        self.layer4 = torch.nn.Sequential(\r\n",
    "            self.fc1,\r\n",
    "            torch.nn.ReLU(),\r\n",
    "            torch.nn.Dropout(p=1 - self.keep_prob))\r\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\r\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = self.layer3(out)\r\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\r\n",
    "        out = self.layer4(out)\r\n",
    "        out = self.fc2(out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# CNN 모델 정의\r\n",
    "model = CNN().to(device)\r\n",
    "\r\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    "total_batch = len(data_loader)\r\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "for epoch in range(training_epochs):\r\n",
    "    avg_cost = 0\r\n",
    "\r\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\r\n",
    "        # image is already size of (28x28), no reshape\r\n",
    "        # label is not one-hot encoded\r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        hypothesis = model(X)\r\n",
    "        cost = criterion(hypothesis, Y)\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        avg_cost += cost / total_batch\r\n",
    "\r\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sswwd\\anaconda3\\envs\\chch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch:    1] cost = 0.191624418\n",
      "[Epoch:    2] cost = 0.0512804389\n",
      "[Epoch:    3] cost = 0.0381360427\n",
      "[Epoch:    4] cost = 0.0297160726\n",
      "[Epoch:    5] cost = 0.0243346617\n",
      "[Epoch:    6] cost = 0.0198972933\n",
      "[Epoch:    7] cost = 0.0179869402\n",
      "[Epoch:    8] cost = 0.0151090175\n",
      "[Epoch:    9] cost = 0.0122152623\n",
      "[Epoch:   10] cost = 0.0120462356\n",
      "[Epoch:   11] cost = 0.0103305001\n",
      "[Epoch:   12] cost = 0.00999995973\n",
      "[Epoch:   13] cost = 0.00960548688\n",
      "[Epoch:   14] cost = 0.00795959495\n",
      "[Epoch:   15] cost = 0.00638818182\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\r\n",
    "with torch.no_grad():\r\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\r\n",
    "    Y_test = mnist_test.test_labels.to(device)\r\n",
    "\r\n",
    "    prediction = model(X_test)\r\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\r\n",
    "    accuracy = correct_prediction.float().mean()\r\n",
    "    print('Accuracy:', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sswwd\\anaconda3\\envs\\chch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\sswwd\\anaconda3\\envs\\chch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9836999773979187\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}