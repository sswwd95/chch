{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. 파이토치 제공 데이터 사용\r\n",
    "2. 같은 클래스 별 폴더 이미지 데이터 이용\r\n",
    "3. 개인 데이터 사용(2 types)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as tr # 데이터를 불러오면서 전처리를 바로 할 수 있게 불러와주는 라이브러리\r\n",
    "from torch.utils.data import DataLoader, Dataset\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "transf = tr.Compose([tr.Resize(8),tr.ToTensor()])\r\n",
    "# 전처리 작업을 Compose 안에 일렬로 해준다.\r\n",
    "# compose = 순서대로 작업해준다.\r\n",
    "# PIL 이미지 형태여야지 사용할 수 있다!!!!!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='A:\\chch\\chchdata\\data', train=True, download=True, transform=transf)\r\n",
    "testset = torchvision.datasets.CIFAR10(root='A:\\chch\\chchdata\\data', train=False, download=True, transform=transf)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "trainset[0][0].size()\r\n",
    "# cifar10이 rgb 채널이라 3, 8, 8이 된다.\r\n",
    "# 파이토치는 채널 수가 앞에 위치한다."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\r\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=True, num_workers=2)\r\n",
    "# num_workers =  데이터로드를 할 때 서브 프로세스를 몇 개를 쓸 것인지 설정 -> 파라미터 튜닝에 해당\r\n",
    "# 고려 사항 : 학습 환경의 GPU개수, CPU개수, I/O 속도, 메모리 등"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "len(trainloader)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "dataiter = iter(trainloader) # 데이터를 하나씩 불러온다는 것\r\n",
    "images, labels = dataiter.next()\r\n",
    "\r\n",
    "images.size()\r\n",
    "#torch.Size([50, 3, 8, 8]) -> 배치사이즈, 채널 수 , 이미지 너비, 이미지 높이"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. 같은 클래스 별 폴더 이미지 데이터 이용"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "transf = tr.Compose([tr.Resize(16), tr.ToTensor()])\r\n",
    "trainset = torchvision.datasets.ImageFolder(root='A:\\\\chch\\\\chchdata\\\\data\\\\gender', transform=transf) \r\n",
    "# './class' 안에 있는 이미지를 자동으로 알아서 찾아주고, 각각의 다른 폴더에 대해 라벨링까지 해준다. transform을 설정해 전처리도 바로 할 수 있다.\r\n",
    "trainloader = DataLoader(trainset, batch_size=10, shuffle=False, num_workers=2)\r\n",
    "print(len(trainloader))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "trainset[0][0].size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 16])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. 개인 데이터 사용(2 types)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# import preprocessing\r\n",
    "train_images = np.random.randint(256,size=(20,32,32,3))\r\n",
    "train_labels = np.random.randint(2, size=(20,1))\r\n",
    "\r\n",
    "# preprocessing..\r\n",
    "# train_images, train_labels = preprocessing(train_images, train_labels)\r\n",
    "print(train_images.shape, train_labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20, 32, 32, 3) (20, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class TensorData(Dataset):\r\n",
    "    def __init__(self, x_data, y_data): # 외부데이터를 받기 위해 x_data, y_data 추가\r\n",
    "        self.x_data = torch.FloatTensor(x_data) # 숫자 속성 정하는 tensor\r\n",
    "        self.x_data = self.x_data.permute(0,3,1,2) \r\n",
    "        # 이미지 개수, 채널 수 , 이미지 너비, 이미지 높이 -> 순서를 바꾸기 위해 permute 사용\r\n",
    "        # (20, 32, 32, 3) -> (20, 3, 32, 32)\r\n",
    "        self.y_data = torch.LongTensor(y_data)  # 숫자 속성 정하는 tensor\r\n",
    "        self.len = self.y_data.shape[0] # 데이터의 개수 산출하기\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        return self.x_data[index], self.y_data[index] # train_data[0][0] \r\n",
    "    def __len__(self):\r\n",
    "        return self.len"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_data = TensorData(train_images, train_labels)\r\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_data[0][0].size() # torch.Size([3, 32, 32]) , x_data만 불러오는 것\r\n",
    "# train_data[0][1].size() #torch.Size([1]) -> y 라벨 값을 불러오는데 0 또는 1 이니까 사이즈는 1\r\n",
    "# train_data[3][1].size() #torch.Size([1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "dataiter = iter(train_loader)\r\n",
    "images, labels = dataiter.next()\r\n",
    "\r\n",
    "images.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. 개인 데이터 사용하는 이유\r\n",
    "- 데이터가 다른 작업도 쓰는 경우에는 dir 함부로 못바꾼다. 파이토치에서 제공하는 transform 의 종류가 비교적 제한적이다. \r\n",
    "- 디테일한 전처리 작업은 파이토치에서 사용하지 않는다. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "개인 데이터에 transform 사용하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "'''\r\n",
    "from torch.utils.data import Dataset\r\n",
    "\r\n",
    "class MyDataset(Dataset):\r\n",
    "    def __init__(self):\r\n",
    "    \r\n",
    "    def __getitem__(self, index):\r\n",
    "    \r\n",
    "    def __len__(self):\r\n",
    "'''\r\n",
    "# 위의 코드를 잘 활용하면 좋다. \r\n",
    "\r\n",
    "class MyDataset(Dataset):\r\n",
    "    def __init__(self, x_data, y_data, transform=None):\r\n",
    "        self.x_data = x_data\r\n",
    "        self.y_data = y_data\r\n",
    "        self.transform = transform\r\n",
    "        self.len = len(y_data)\r\n",
    "    def __getitem__(self, index): # getitem은 튜플형태로 데이터를 내보내준다.\r\n",
    "        sample = self.x_data[index], self.y_data[index]\r\n",
    "        if self.transform: # 전처리를 해서 내보낸다.\r\n",
    "            sample = self.transform(sample)\r\n",
    "        return sample\r\n",
    "    def __len__(self):\r\n",
    "        return self.len\r\n",
    "\r\n",
    "class ToTensor:\r\n",
    "    def __call__(self, sample):\r\n",
    "        inputs, labels = sample\r\n",
    "        inputs = torch.FloatTensor(inputs)\r\n",
    "        inputs = inputs.permute(2,0,1)\r\n",
    "        return inputs, torch.LongTensor(labels)\r\n",
    "\r\n",
    "class LinearTensor:\r\n",
    "    def __init__(self, slope=1, bias=0): \r\n",
    "        self.slope = slope\r\n",
    "        self.bias = bias\r\n",
    "\r\n",
    "    def __call__(self, sample):\r\n",
    "        inputs, labels = sample\r\n",
    "        inputs = self.slope*inputs + self.bias #원하는 계산 기입\r\n",
    "        return inputs, labels\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "trans = tr.Compose([ToTensor(),LinearTensor(2,5)])\r\n",
    "ds1 = MyDataset(train_images, train_labels, transform=trans)\r\n",
    "train_loader1 = DataLoader(ds1, batch_size=10, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "first_data = ds1[0]\r\n",
    "features, labes = first_data\r\n",
    "print(type(features), type(labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "dataiter1 = iter(train_loader1)\r\n",
    "images1, labels1 = dataiter1.next()\r\n",
    "\r\n",
    "# images1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "위에는 numpy형태라 tr.Compose를 사용하면 에러가 난다. \r\n",
    "tr을 꼭 사용하고 싶다면 아래 방식을 이용."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}