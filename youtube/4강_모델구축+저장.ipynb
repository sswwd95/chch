{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "load data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "transform = transforms.Compose(\r\n",
    "    [transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
    "\r\n",
    "trainset = torchvision.datasets.CIFAR10(root='A:/chchdata/data/', train=True, download=True, transform = transform)\r\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle = True, num_workers=2)\r\n",
    "testset = torchvision.datasets.CIFAR10(root='A:/chchdata/data/', train = False, download=True, transform=transform)\r\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=True, num_workers=2)\r\n",
    "\r\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer','dog','frog','horse','ship','truck')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to A:/chchdata/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting A:/chchdata/data/cifar-10-python.tar.gz to A:/chchdata/data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "class Net(nn.Module):  # nn.modules를 상속 받는다\r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\r\n",
    "        self.fc2 = nn.Linear(120, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 10) # 클래스 10개\r\n",
    "    \r\n",
    "    def forward(self, x): # x가 input\r\n",
    "        x = self.pool(F.relu(self.conv1(x)))\r\n",
    "        x = self.pool(F.relu(self.conv2(x)))\r\n",
    "        x = x.view(-1, 16 * 5 * 5) # 일자로 피는 작업\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "net = Net()\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) \r\n",
    "for epoch in range(1) :\r\n",
    "    running_loss = 0.0\r\n",
    "    for i, data in enumerate(trainloader, 0): \r\n",
    "        # get the inputs; data is a list of [inputs, labels]\r\n",
    "        inputs, labels = data\r\n",
    "\r\n",
    "        # zero the parameter gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # forward + backward + optimizer\r\n",
    "        outputs = net(inputs)\r\n",
    "        loss = criterion(outputs, labels) # crossentropyloss\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step() # 옵티마이저 계산\r\n",
    "\r\n",
    "        # print statistics\r\n",
    "        running_loss += loss.item()\r\n",
    "        if i % 2000 == 1999 :\r\n",
    "            print('[%d, %5d] loss: %.3f' % \r\n",
    "            (epoch + 1, i + 1, running_loss / 2000))\r\n",
    "            running_loss = 0.0\r\n",
    "    \r\n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sswwd\\anaconda3\\envs\\chch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,  2000] loss: 2.150\n",
      "[1,  4000] loss: 1.777\n",
      "[1,  6000] loss: 1.596\n",
      "Finished Training\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델 저장"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "PATH = 'A:\\chchdata\\h5\\cifar_net.pth'  # 모델에서 나온 가중치를 저장할 경로 지정\r\n",
    "torch.save(net.state_dict(), PATH) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "load model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "net = Net()\r\n",
    "net.load_state_dict(torch.load(PATH))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "correct = 0\r\n",
    "total = 0\r\n",
    "with torch.no_grad():   # 추적 안함. 업데이트 x\r\n",
    "    for data in testloader:\r\n",
    "        images, labels = data\r\n",
    "        outputs = net(images)\r\n",
    "        _, predicted = torch.max(outputs.data, 1) # 10개의 클래스에서 가장 큰 값으로 예측 ==argmax\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels).sum().item()\r\n",
    "\r\n",
    "print('Accuracy of the network on the 10000 test images : %d %%' % (\r\n",
    "    100 * correct / total))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images : 45 %\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}